# 인덱스
쿼리튜닝
- 랜덤 I/O 자체를 줄여주는 것이 목적이다. 
- 쿼리 튜닝을 한다고 해서 랜덤 I/O를 순차 I/O로 실행할 방법은 많지 않다.

## 인덱스
데이터 저장
- 인덱스: Sorted Array 자료구조를 사용. 항상 정렬된 상태를 유지한다
- 데이터 파일: Array List 처럼 넣는대로 저장된다. InnoDB는 PK 기준으로 정렬되어 저장된다. 

인덱스는 정렬된 상태를 유지해야하기 때문에 Insert, Update, Delete는 처리가 느리지만, 조회는 빠르다. 

## B-tree 인덱스
구조 및 특징
- 최상위에 루트 노드. 중간에 브랜치 노드. 마지막에 리프노드
- 인덱스의 리프노드는 실제 데이터를 찾기 위한 주소 값을 가진다
   - InnoDB는 PK에 의해서 클러스터링되기 때문에 PK 값 자체가 주소 역할을 한다

인덱스 키 추가
- 저장된 키 값을 이용해서 적당한 위치를 찾고, 레코드의 키값과 대상 주소 정보를 리프노드에 저장한다
- 리프노드에 공간이 없으면 노드가 분리되어야하는데, 이때는 상위 브랜치 노드까지 영향범위가 넓어진다
- InnoDB의 경우는 인덱스 키 추가를 바로 할 지, 지연처리할 지 선택할 수 있다
   - 버퍼 풀에 새로운 키 값을 추가해야할 페이지가 존재한다면 즉시 처리한다
   - 그게 아니라면 '인서트 버퍼'에 추가하고 백그라운드 작업으로 처리된다

인덱스 키 삭제
- 키 값이 저장된 리프노드를 찾아서 삭제 마크만 하면 완료된다

인덱스 키 변경
- 키 값을 삭제하고, 새로 추가하는 형태로 처리된다

키 검색
- 인덱스를 이용한 검색은 100% 일치 또는 앞 부분이 일치할 경우에 사용할 수 있다. 부등호 비교나 뒷부분이 일치하는 경우는 검색이 불가능하다
- 인덱스의 값이 변형된 후 비교될 경우에는 인덱스를 탈 수 없다

인덱스 키 값의 크기
- 페이지: 디스크에 데이터를 저장하는 가장 기본 단위.
   - 디스크의 모든 읽기 및 쓰기 작업의 최소 작업 단위
   - 버퍼풀에서 데이터를 버퍼링하는 기본 단위
   - InnoDB의 페이지 크기는 16KB로 고정
- 예: 인덱스 키가 16바이트라면?
   - 1개 정보는 키-16바이트 + 주소-약12바이트를 저장할 수 있다
   - 16*1024/(16+12) = 585개
   - 만약에 인덱스 키의 크기가 더 커진다면 1개 페이지에 저장할 수 있는 인덱스의 개수는 더 줄어든다 -> 디스크를 읽는 횟수가 더 늘어난다

선택도(Selectivity, 기수성(Cardinality)
- 모든 인덱스의 키 값 가운데 유니크한 값의 수를 의미한다. 
   - 전체 인덱스 키 값은 100개인데, 유니크한 값의 수가 10개라면 선택도는 10이다
- 인덱스는 선택도가 높을 수록 검색 대상이 줄어들기 때문에, 그만큼 빠르게 처리된다

레코드 건수 선택
- 인덱스를 통해 데이터를 읽을 때는, 그냥 데이터를 읽을 때보다 비용이 더 비싸며 보통 4-5배 정도 더 비용이 든다
- 그 기준으로보면 읽어야할 레코드의 건수가 전체 테이블의 20~25%를 넘어서면 풀스캔을 하는게 더 이득일 수 있다

인덱스 스캔
1. 레인지 스캔
   - 검색해야할 인덱스의 범위가 정해졌을 때 사용하는 방법. 시작할 위치를 찾으면 그때부터는 범위에 맞을 때까지 계속 검색한다
   - 리프노드에서 검색된 데이터는 데이터페이지에서 가져오는게 필요한데, 이때 건 단위로 랜덤 I/O가 발생한다
2. 인덱스 풀 스캔
   - 인덱스의 처음부터 끝까지 읽는 경우
   - 예: count(*) 또는 select 항목에 index 데이터를 사용
3. 루스 인덱스 스캔
   - 데이터를 읽어오다가 중간에 점프하고 일정 범위 이후에 다시 데이터를 읽어오는 방식
   - 예: `select a, min(b)` 와 같은 쿼리의 경우 a, b로 인덱스가 되어 있다면 a의 특정 값에 해당하는 min(b)를 찾으면 그 다음 값을 찾을 때까지 점프할 수 있다

다중칼럼 인덱스
- n개 칼럼이 B-tree index의 구조를 가진다
- 인덱스의 순서에 따라서 데이터가 저장되기 때문에, 정렬 방향이 중요하다

인덱스의 정렬
- multi column에서는 정렬을 지원하지 않는다. ASC, DESC를 지정할 수 있지만 무시하고 오름차순으로만 정렬된다 -> 이후 변경될 구현에 대비해서 스펙만 있는 것. 실제로는 모두 ASC로 생성된다
   ```
   https://dev.mysql.com/doc/refman/8.0/en/create-index.html
   ASC and DESC are also not supported for multi-valued indexes
   ```
- 그럼 실제로 비슷한 상황이 발생할 때에는 어떻게 해야할까? 꼭 필요하다면 하나의 값을 음수로 저장하면 사용할 수 있다

인덱스 스캔 방향
- 인덱스를 앞으로 또는 뒤에서부터 읽는 방법을 통해서 읽어올 수 있다
- 예를 들어서 `DESC LIMIT 1`의 경우, 앞에서부터 읽으면 모든 데이터를 읽어야하지만, 뒤에서부터 읽으면 1건만 읽으면 된다

인덱스의 사용성과 효율성
- 인덱스 조건 (공식 용어는 아니다)
   1. 작업 범위 결정 조건: 인덱스가 특정 값을 지정하는 범위의 결정 조건이 될 경우. 많을 수록 성능이 올라간다.
   2. 필터링 조건 또는 체크 조건: 인덱스가 특정 값을 필터링 하는 조건으로 사용되는 경우. 최종적으로 조회되는 항목을 줄일 지는 몰라도, 처리 성능을 올려주지는 않는다.
- 인덱스를 사용할 수 없는 경우
   1. not-equal로 비교된 경우
      ```
      <>, not in, not between, is not null
      ```
   2. like '%??'
   3. 특정 연산으로 인덱스 칼럼의 값이 변경된 경우
   4. 데이터 타입이 서로 다른 비교 (인덱스 칼럼의 타입을 변경해야 비교가 가능한 경우)
      ```
      where char_column = 10;
      ```
   5. 문자열 데이터 타입의 콜레이션이 다를 경우
- mysql에서는 null도 index로 관리된다

## 클러스터링 인덱스
개념
- PK에만 적용된다
- PK 키 값이 비슷한 레코드끼리 묶어서 저장하는 것을 클러스터링 인덱스
- PK 키 값에 의해서 저장 위치가 결정되기 때문에 인덱스 알고리즘 보다 테이블 레코드의 저장방식이라고도 볼 수 있다

특징
- InnoDB는 항상 클러스터링 인덱스로 저장된다. PK 기반의 검색이 매우 빠르나 레코드의 저장이나 PK의 변경이 상대적으로 느리다
- 일반 인덱스와 달리 리프노드에 레코드의 모든 칼럼이 있다. 

클러스터 인덱스 우선순위
1. PK
2. not null 옵션의 unique index 중에서 첫번째 인덱스를 지정
3. 내부적으로 자동으로 증가하는 칼럼을 할당하고, 이를 클러스터키로 정한다

뵤조 인덱스와의 관계
- 인덱스의 마지막 리프노드는 해당 레코드가 저장된 주소가 아니라 PK 값을 저장하도록 구현돼있다. 
   - 이로 인해서 PK 변경이 있을 때 보조 인덱스가 영향을 받지 않도록 한다. 
   ```sql
   # first_name은 인덱스
   # first_name 기준으로 PK 값을 찾고, 다시한번 PK로 데이터를 조회한다
   select * from emplyees where first_name = 'Aamer';
   ```

장점
- PK로 검색하면 속도가 굉장히 빠르다
- 커버링 인덱스의 속도

단점
- 보조 인덱스가 모두 클러스터 키를 갖기 때문에 크 값이 크면 인덱스의 크기가 커진다
- 보조 인덱스로 검색하면 PK로 다시 검색해야 하기 때문에 속도가 조금 느리다
- PK를 변경할 때, delete & insert가 발생하기 때문에 속도가 느리다

## 유니크 인덱스
개념
- 인덱스와 동일한 기능을 하는데, 제약조건에 대한 체크 기능이 추가된다

특징
- null도 저장될 수 있는데, null은 2개 이상 저장할 수 있다
- 성능이 좋아질 목적으로 불필요하게 유니크인덱스를 추가하지는 않는다

읽기 속도
- 유니크하지 않은 보조 인덱스는 중복된 값을 더 읽어와야하기 때문에 느린것이지, 인덱스 자체의 속도 차이는 없다

인덱스 쓰기
- 중복된 키 값이 있는지 체크하는 과정이 있기 때문에, 일반 보조 인덱스보다는 느리다

## 기타 특징
통계 정보
- mysql의 통계 정보는 자주 업데이트된다. 예: 테이블을 처음 열거나 대량의 데이터 변경 또는 DDL 작업 이후
- 통계 정보가 크게 잘못될 때는, 'ANALYZE'명령으로 정보를 다시 수집해보는 것이 좋다

Cardinality
- column의 값들이 얼마나 유니크한지를 알려주는 값
- 값이 높으면 Cardinality가 높다고 말하고, 그만큼 유니크한 값이 많다는 뜻이다
- 확인
   ```sql
   # 조회
   show index from <<table>>

   # 결과
   +-----+----------+----------------------------+-----------+-----------+----------+
   |Table|Non_unique|Key_name                    |Column_name|Cardinality|Index_type|
   +-----+----------+----------------------------+-----------+-----------+----------+
   |USERS|0         |PRIMARY                     |id         |110787     |BTREE     |
   |USERS|0         |UK_dc4eq7plr20fdhq528twsak1b|username   |110853     |BTREE     |
   |USERS|1         |IDX_DELETEDAT               |deletedat  |18330      |BTREE     |
   +-----+----------+----------------------------+-----------+-----------+----------+
   ```